{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import emoji\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def read_csv(filename = 'data/emojify_data.csv'):\n",
    "    phrase = []\n",
    "    emoji = []\n",
    "\n",
    "    with open (filename) as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile)\n",
    "\n",
    "        for row in csvReader:\n",
    "            phrase.append(row[0])\n",
    "            emoji.append(row[1])\n",
    "\n",
    "    X = np.asarray(phrase)\n",
    "    Y = np.asarray(emoji, dtype=int)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train=read_csv('data/train_emoji.csv')\n",
    "X_test,Y_test=read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 132)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 56)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen=len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":smile:\",\n",
    "                    \"3\": \":disappointed:\",\n",
    "                    \"4\": \":fork_and_knife:\"}\n",
    "\n",
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miss you so much â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "index=3\n",
    "print(X_train[index], end=\" \")\n",
    "print(label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love my dad â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "index=100\n",
    "print(X_train[index], end=\" \")\n",
    "print(label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this guy was such a joke ðŸ˜„\n"
     ]
    }
   ],
   "source": [
    "index=101\n",
    "print(X_train[index], end=\" \")\n",
    "print(label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(X,C):\n",
    "    return np.eye(C)[X.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train=convert_to_one_hot(Y_train,C=5)\n",
    "Y_oh_test=convert_to_one_hot(Y_test,C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132, 5), (56, 5))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_oh_train.shape, Y_oh_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n",
    "\n",
    "# words=List of word in the vocabulary\n",
    "# words_to_index, index_to_words= dictionary for index and word\n",
    "# word_to_vec_map= vector representation for the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of the word \"cucumber\" is 113317.\n",
      "The word having index 285565 is pisz\n"
     ]
    }
   ],
   "source": [
    "word='cucumber'\n",
    "index=285565\n",
    "print('The index of the word \"{}\" is {}.'.format(word,word_to_index[word]))\n",
    "print('The word having index {} is {}'.format(index,index_to_word[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model=> All words of the sentence are converted into vectors and then average is taken. Softmax is applied on \n",
    "# that average and Class is classified.\n",
    "\n",
    "def average_of_sentence(sentence,word_to_vec_map):\n",
    "    \n",
    "    words=list(sentence.split())\n",
    "    words=[x.lower() for x in words]\n",
    "    \n",
    "    word1=list(word_to_vec_map.keys())[0]\n",
    "    avg=np.zeros(word_to_vec_map[word1].shape)\n",
    "    \n",
    "    for w in words:\n",
    "        avg+=word_to_vec_map[w]\n",
    "    avg=avg/len(words)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, Y, W, b, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Given X (sentences) and Y (emoji indices), predict emojis and compute the accuracy of your model over the given set.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data containing sentences, numpy array of shape (m, None)\n",
    "    Y -- labels, containing index of the label emoji, numpy array of shape (m, 1)\n",
    "    \n",
    "    Returns:\n",
    "    pred -- numpy array of shape (m, 1) with your predictions\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    pred = np.zeros((m, 1))\n",
    "    \n",
    "    for j in range(m):                       # Loop over training examples\n",
    "        \n",
    "        # Split jth test example (sentence) into list of lower case words\n",
    "        words = X[j].lower().split()\n",
    "        \n",
    "        # Average words' vectors\n",
    "        avg = np.zeros((50,))\n",
    "        for w in words:\n",
    "            avg += word_to_vec_map[w]\n",
    "        avg = avg/len(words)\n",
    "\n",
    "        # Forward propagation\n",
    "        Z = np.dot(W, avg) + b\n",
    "        A = softmax(Z)\n",
    "        pred[j] = np.argmax(A)\n",
    "        \n",
    "    print(\"Accuracy: \"  + str(np.mean((pred[:] == Y.reshape(Y.shape[0],1)[:]))))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z=W*avg+b\n",
    "# a=softmax(z)\n",
    "# loss=sum(Y_oh*log(a))\n",
    "\n",
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    np.random.seed(1)\n",
    "    m=Y.shape[0]     # Number of training examples\n",
    "    n_y=5            # Number of classes\n",
    "    n_h=50           # Dimensions of Glove vectors\n",
    "    \n",
    "    W=np.random.randn(n_y,n_h)/np.sqrt(n_h)\n",
    "    b=np.zeros(n_y,)\n",
    "    \n",
    "    Y_oh=convert_to_one_hot(Y,C=5)\n",
    "    \n",
    "    # Optimization function\n",
    "    for t in range(num_iterations):\n",
    "        cost=0\n",
    "        for i in range(m):\n",
    "            avg=average_of_sentence(X[i],word_to_vec_map)\n",
    "            \n",
    "            # Forward Propagation\n",
    "            z=np.dot(W,avg)+b\n",
    "            a=softmax(z)\n",
    "            \n",
    "            # Loss calculations\n",
    "            cost+=-np.sum(np.multiply(Y_oh[i],np.log(a)))\n",
    "            \n",
    "            # Backpropagation\n",
    "            dz=a-Y_oh[i]\n",
    "            dW=np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "            \n",
    "            # Updating Parameters\n",
    "            W=W - learning_rate*dW\n",
    "            b=b - learning_rate*db\n",
    "            \n",
    "        cost=cost/m\n",
    "        \n",
    "        if t%100==0:\n",
    "            print('Cost after iterations {} is {}'.format(t,cost))\n",
    "            pred= predict(X, Y, W, b, word_to_vec_map)\n",
    "    \n",
    "    return pred,W,b\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iterations 0 is 1.6461697922094756\n",
      "Accuracy: 0.3484848484848485\n",
      "Cost after iterations 100 is 0.3967869591827299\n",
      "Accuracy: 0.9318181818181818\n",
      "Cost after iterations 200 is 0.287864684355277\n",
      "Accuracy: 0.9545454545454546\n",
      "Cost after iterations 300 is 0.2372234531131005\n",
      "Accuracy: 0.9696969696969697\n"
     ]
    }
   ],
   "source": [
    "pred,W,b=model(X_train, Y_train, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9772727272727273\n",
      "Test set:\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
